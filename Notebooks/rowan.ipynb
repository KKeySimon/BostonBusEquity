{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9bc625-83a9-4e33-b697-7cff3c9d981e",
   "metadata": {},
   "source": [
    "## If there are service level disparities, are there differences in the racial characteristics of the people most impacted?\n",
    "\n",
    "This section looks to help expand on our third question: \n",
    "- Are there disparities in the service levels of different routes (which lines are late more often than others)? \n",
    "\n",
    "To do so we will be looking at racial data from the [2020 Census Tracts in Boston](https://data.boston.gov/dataset/2020-census-tracts-in-boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598055f4-59eb-4921-9dfd-d09365360f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647efe22-998c-4edd-bdf2-2c88d47eb2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Columns: ['FILEID', 'STUSAB', 'SUMLEV', 'GEOID', 'GEOCODE', 'REGION', 'DIVISION', 'STATE', 'COUNTY', 'COUSUB', 'TRACT', 'P0020001', 'P0020005', 'P0020006', 'P0020002', 'P0020008', 'P0020007', 'P0020009', 'P0020010', 'P0020011', 'P0040001', 'P0040005', 'P0040006', 'P0040002', 'P0040008', 'P0040007', 'P0040009', 'P0040010', 'P0040011', 'P0050001', 'P0050002', 'P0050003', 'P0050004', 'P0050005', 'P0050006', 'P0050007', 'P0050008', 'P0050009', 'P0050010', 'H0010001', 'H0010002', 'H0010003']\n",
      "Renamed Columns: ['fileid', 'stusab', 'sumlev', 'Census_Tract_ID', 'Tract_Code', 'region', 'division', 'state', 'county', 'cousub', 'Tract_Number', 'Total_Population', 'Black_Population', 'Native_Population', 'White_Population', 'Pacific_Population', 'Asian_Population', 'Other_Race_Population', 'Two_or_More_Races', 'p0020011', 'p0040001', 'p0040005', 'p0040006', 'Hispanic_Population', 'p0040008', 'p0040007', 'p0040009', 'p0040010', 'p0040011', 'p0050001', 'p0050002', 'p0050003', 'p0050004', 'p0050005', 'p0050006', 'p0050007', 'p0050008', 'p0050009', 'p0050010', 'Total_Housing_Units', 'Occupied_Housing_Units', 'Vacant_Housing_Units']\n",
      "Cleaned census data saved as 'cleaned_2020_census_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# census raw data\n",
    "file_path = \"data/census-tract-data.csv\"  # Update this if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Original Columns:\", df.columns.tolist())\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "\n",
    "# rename columns\n",
    "column_mapping = {\n",
    "    \"geoid\": \"Census_Tract_ID\",\n",
    "    \"geocode\": \"Tract_Code\",\n",
    "    \"tract\": \"Tract_Number\",\n",
    "    \"p0020001\": \"Total_Population\",\n",
    "    \"p0020002\": \"White_Population\",\n",
    "    \"p0020005\": \"Black_Population\",\n",
    "    \"p0020006\": \"Native_Population\",\n",
    "    \"p0020007\": \"Asian_Population\",\n",
    "    \"p0020008\": \"Pacific_Population\",\n",
    "    \"p0020009\": \"Other_Race_Population\",\n",
    "    \"p0020010\": \"Two_or_More_Races\",\n",
    "    \"p0040002\": \"Hispanic_Population\",\n",
    "    \"h0010001\": \"Total_Housing_Units\",\n",
    "    \"h0010002\": \"Occupied_Housing_Units\",\n",
    "    \"h0010003\": \"Vacant_Housing_Units\"\n",
    "}\n",
    "\n",
    "# check for actual existing columns\n",
    "existing_columns = {col: new_col for col, new_col in column_mapping.items() if col in df.columns}\n",
    "df = df.rename(columns=existing_columns)\n",
    "\n",
    "print(\"Renamed Columns:\", df.columns.tolist())\n",
    "\n",
    "# drop unecessary columns\n",
    "drop_columns = [\"fileid\", \"stusab\", \"sumlev\", \"region\", \"division\", \"state\", \"county\", \"cousub\"]\n",
    "df = df.drop(columns=[col for col in drop_columns if col in df.columns], errors=\"ignore\")\n",
    "\n",
    "# convert numeric columns to useful names\n",
    "numeric_cols = list(existing_columns.values())\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# handle missing data columns\n",
    "if \"Total_Population\" in df.columns:\n",
    "    df = df.dropna(subset=[\"Total_Population\"])\n",
    "else:\n",
    "    print(\"'Total_Population' column not found.\")\n",
    "\n",
    "# calculate demographic percentages\n",
    "race_columns = []\n",
    "if \"White_Population\" in df.columns:\n",
    "    df[\"Percent_White\"] = (df[\"White_Population\"] / df[\"Total_Population\"]) * 100\n",
    "    race_columns.append(\"Percent_White\")\n",
    "if \"Black_Population\" in df.columns:\n",
    "    df[\"Percent_Black\"] = (df[\"Black_Population\"] / df[\"Total_Population\"]) * 100\n",
    "    race_columns.append(\"Percent_Black\")\n",
    "if \"Hispanic_Population\" in df.columns:\n",
    "    df[\"Percent_Hispanic\"] = (df[\"Hispanic_Population\"] / df[\"Total_Population\"]) * 100\n",
    "    race_columns.append(\"Percent_Hispanic\")\n",
    "if \"Asian_Population\" in df.columns:\n",
    "    df[\"Percent_Asian\"] = (df[\"Asian_Population\"] / df[\"Total_Population\"]) * 100\n",
    "    race_columns.append(\"Percent_Asian\")\n",
    "if all(x in df.columns for x in [\"Native_Population\", \"Pacific_Population\", \"Other_Race_Population\", \"Two_or_More_Races\"]):\n",
    "    df[\"Percent_Other\"] = ((df[\"Native_Population\"] + df[\"Pacific_Population\"] +\n",
    "                            df[\"Other_Race_Population\"] + df[\"Two_or_More_Races\"]) / df[\"Total_Population\"]) * 100\n",
    "    race_columns.append(\"Percent_Other\")\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# normalize percentages and remove extremely low populations\n",
    "if len(race_columns) > 0:\n",
    "    df[\"Total_Percent\"] = df[race_columns].sum(axis=1)\n",
    "    df.loc[df[\"Total_Percent\"] > 100, race_columns] = df.loc[df[\"Total_Percent\"] > 100, race_columns].div(df[\"Total_Percent\"], axis=0) * 100\n",
    "    df = df.drop(columns=[\"Total_Percent\"])\n",
    "\n",
    "# \n",
    "df = df[df[\"Total_Population\"] >= 10]\n",
    "\n",
    "df[race_columns] = df[race_columns].round(2)\n",
    "\n",
    "# save cleaned data\n",
    "output_file = \"cleaned_2020_census_data.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned census data saved as '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae628ae-b243-430c-8139-74b2f25d3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import pyppeteer\n",
    "\n",
    "# Set the environment variable early\n",
    "os.environ[\"PYPPETEER_CHROME_EXECUTABLE\"] = r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "\n",
    "# Monkey-patch pyppeteer.launch to force the executablePath parameter\n",
    "_original_launch = pyppeteer.launch\n",
    "async def patched_launch(*args, **kwargs):\n",
    "    kwargs['executablePath'] = os.environ[\"PYPPETEER_CHROME_EXECUTABLE\"]\n",
    "    return await _original_launch(*args, **kwargs)\n",
    "pyppeteer.launch = patched_launch\n",
    "\n",
    "url = \"https://www.ctps.org/dv/mbtasurvey2018/index.html#navButton\"\n",
    "session = HTMLSession()\n",
    "response = session.get(url)\n",
    "\n",
    "# Render the page and simulate clicking the different tabs.\n",
    "click_script = \"document.getElementById('oth_demo').click();\" # Change this to the appropriate ID for the tab you want to click\n",
    "response.html.render(script=click_script, timeout=20)\n",
    "\n",
    "# Wait a bit for the fare data to load after the click\n",
    "time.sleep(20) # Needed to change to 20 to load everything\n",
    "\n",
    "# Save HTML for debugging\n",
    "with open(\"rendered_tab.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.html.html)\n",
    "\n",
    "soup = BeautifulSoup(response.html.html, 'html.parser')\n",
    "text_elements = soup.select(\"text.chartNum\")\n",
    "print(\"Found\", len(text_elements), \"text elements with class 'chartNum'\")\n",
    "\n",
    "data = []\n",
    "for text_el in text_elements:\n",
    "    classes = text_el.get(\"class\", [])\n",
    "    route = None\n",
    "    # Look for the class that starts with 'r' (excluding \"chartNum\")\n",
    "    for cls in classes:\n",
    "        if cls != \"chartNum\" and cls.startswith(\"r\"):\n",
    "            route = cls[1:]  # Remove the \"r\" prefix\n",
    "            break\n",
    "    if route:\n",
    "        percent = text_el.get_text(strip=True)\n",
    "        data.append((route, percent))\n",
    "\n",
    "# Sort the data\n",
    "data_sorted = sorted(data, key=lambda tup: (0 if \"line-all\" in tup[0].lower() else 1, tup[0]))\n",
    "\n",
    "# Write the sorted data\n",
    "output_filename = \"other_demographics_data.txt\" # Change the filename as necessary\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "    for route, percent in data_sorted:\n",
    "        file.write(f\"Route {route}: {percent}\\n\")\n",
    "\n",
    "print(f\"Fare data saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
